# -*- coding: utf-8 -*-
"""Movie prediction success

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pr5k9kLOiFkRWklb88LasKviN_Gc8ZmF
"""

#Project of ML
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#Movie Success Prediction
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

from sklearn.model_selection import train_test_split,learning_curve
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import(accuracy_score,confusion_matrix,classification_report,roc_curve,auc,precision_recall_curve)
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.svm import SVC

#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# 1 Create Dataset
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

df = pd.read_csv("movie_data.csv")

#-----------------------------------------------------------
# 2 Encoding
#---------------------------------------------------------
le = LabelEncoder()
for col in['Genre','Release_Season','Status']:
  df[col] = le.fit_transform(df[col])

#----------------------------------------------------------------
# 3 Attractive Visualizations
#-----------------------------------------------------------------

# Count Plot
plt.figure()
sns.countplot(x=df['Status']) # Corrected from 'status' to 'Status'
plt.title("Movie Status Distribution (0=Flop, 1=Hit)")
plt.show()

# Box PLot
plt.figure()
sns.boxplot(x=df['Status'],y=df['Budget'])
plt.title("Budget vs Movie Status")
plt.show()

#CorreLation Heatmap
plt.figure()
sns.heatmap(df.corr(),annot=True)
plt.title("Correlation Heatmap")
plt.show()

#------------------------------------------------------------------------------
# 4 Train -test split
#------------------------------------------------------------------------------

x = df.drop('Status',axis=1)
y = df['Status']

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)

models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "SVM":SVC(probability=True),
    "Gradient Boosting": GradientBoostingClassifier()
}
accuracies = {}
roc_data = {}

for name,model in models.items():
    model.fit(x_train,y_train)
    y_pred = model.predict(x_test)
    acc = accuracy_score(y_test,y_pred)
    accuracies[name] = acc

    y_prob = model.predict_proba(x_test)[:,1]
    fpr,tpr, _ = roc_curve(y_test,y_prob)
    roc_auc = auc(fpr,tpr)
    roc_data[name] = (fpr,tpr,roc_auc)

    print(f"\n{name} Accuracy:",acc)

#-----------------------------------------------------------------------
# 6 Accuracy Comparison Graph
#-------------------------------------------------------------------------

plt.figure()
plt.bar(accuracies.keys(),accuracies.values())
plt.xticks(rotation=45)
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.show()

plt.figure()
for name,(fpr,tpr,roc_auc) in roc_data.items():
    plt.plot(fpr,tpr, label=f"{name} (AUC={roc_auc:.2f})")

plt.plot([0,1],[0,1],linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend()
plt.show()

#---------------------------------------
#8 Select Best Model
#---------------------------------------


best_model_name = max(accuracies,key=accuracies.get)
best_model = models[best_model_name]

print("\nBest Model:",best_model_name)

#----------------------------------------
#9 Confusion Matrix

y_pred = best_model.predict(x_test)
cm = confusion_matrix(y_test,y_pred)

plt.figure()
sns.heatmap(cm,annot=True,fmt="d",cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

print("\nClassification Report:\n"),
print(classification_report(y_test,y_pred))

#--------------------------------------------
#10 Feature Importance(if availabele)
#--------------------------------------------

if hasattr(best_model,'feature_importances_'):
    plt.figure()
    plt.bar(x.columns,best_model.feature_importances_)
    plt.title("Feature Importance")
    plt.show()

#----------------------------------------------
#11 Learning Curve
#----------------------------------------------

train_sizes,train_scores,test_scores = learning_curve(best_model,x_train,y_train,cv=5)
plt.figure()
plt.plot(train_sizes,np.mean(train_scores,axis=1))
plt.plot(train_sizes,np.mean(test_scores,axis=1))
plt.title("Learning Curve")
plt.xlabel("Training Size")
plt.ylabel("Score")
plt.show()

# Calculate probability scores for the best model for Precision-Recall curve
y_prob_best_model = best_model.predict_proba(x_test)[:, 1]
precision,recall,_= precision_recall_curve(y_test,y_prob_best_model)

plt.figure()
plt.plot(recall,precision)
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.show()

#-------------------------------------------------
#13 Save Best Model
#-------------------------------------------------

joblib.dump(best_model,"best_movie_model.pkl")
print("\nModel saved as best_movie_model.pkl")